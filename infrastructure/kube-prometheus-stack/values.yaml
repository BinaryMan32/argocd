kube-prometheus-stack:

  # k3s has all of these components in a single process
  # metrics already collected by kubelet
  # see https://github.com/k3s-io/k3s/issues/3619#issuecomment-1425852034
  kubeControllerManager:
    enabled: false
  kubeProxy:
    enabled: false
  kubeScheduler:
    enabled: false
  kubelet:
    serviceMonitor:
      metricRelabelings:
        # k3s exposes all metrics on all endpoints, relabel jobs that belong to other components
        - action: replace
          sourceLabels: [__name__]
          regex: "scheduler_(.+)"
          targetLabel: "job"
          replacement: "kube-scheduler"
        - action: replace
          sourceLabels: [__name__]
          regex: "kubeproxy_(.+)"
          targetLabel: "job"
          replacement: "kube-proxy"

  alertmanager:
    config:
      global:
        slack_api_url_file: /etc/alertmanager/secrets/slack-api/url

      receivers:
        - name: "null"
        - name: fbs-slack
          slack_configs:
            - channel: #devops
              send_resolved: true
              # Message template from https://grafana.com/blog/2020/02/25/step-by-step-guide-to-setting-up-prometheus-alertmanager-with-slack-pagerduty-and-gmail/
              icon_url: https://avatars3.githubusercontent.com/u/3380462
              title: |-
                [{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ .CommonLabels.alertname }} for {{ .CommonLabels.job }}
                {{- if gt (len .CommonLabels) (len .GroupLabels) -}}
                  {{" "}}(
                  {{- with .CommonLabels.Remove .GroupLabels.Names }}
                    {{- range $index, $label := .SortedPairs -}}
                      {{ if $index }}, {{ end }}
                      {{- $label.Name }}="{{ $label.Value -}}"
                    {{- end }}
                  {{- end -}}
                  )
                {{- end }}
              text: >-
                {{ range .Alerts -}}
                *Alert:* {{ .Annotations.summary }}{{ if .Labels.severity }} - `{{ .Labels.severity }}`{{ end }}

                *Description:* {{ .Annotations.description }} {{ if .Annotations.runbook_url }}(<{{ .Annotations.runbook_url }}|Runbook>){{ end }}

                *Details:*
                  {{ range .Labels.SortedPairs }} â€¢ *{{ .Name }}:* `{{ .Value }}`
                  {{ end }}
                {{ end }}

      # https://prometheus.io/docs/alerting/latest/configuration/#route
      route:
        group_by: ['namespace']
        group_wait: 30s
        group_interval: 5m
        repeat_interval: 2h
        receiver: fbs-slack
        routes:
          # Some alert types should be sent to null
          # https://runbooks.prometheus-operator.dev/runbooks/general/infoinhibitor/
          # https://runbooks.prometheus-operator.dev/runbooks/general/watchdog/
          - receiver: 'null'
            matchers:
              - alertname =~ "InfoInhibitor|Watchdog"

    alertmanagerSpec:
      storage:
        volumeClaimTemplate:
          spec:
            storageClassName: longhorn
            accessModes: ["ReadWriteOnce"]
            resources:
              requests:
                storage: 2Gi
      secrets:
        - slack-api

  grafana:
    admin:
      existingSecret: "grafana-login"
    persistence:
      enabled: true
      storageClassName: longhorn
      size: 2Gi

  prometheus:
    prometheusSpec:
      storageSpec:
        volumeClaimTemplate:
          spec:
            storageClassName: longhorn
            accessModes: ["ReadWriteOnce"]
            resources:
              requests:
                storage: 50Gi
